---
title: "Analisi Mercato Immobiliare Texas"
author: "Giuseppe Sinatra"
date: "2024-12-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# 0. Load dataset

```{r}
real_estate_df <- read.csv("realestate_texas.csv", stringsAsFactors = TRUE)
print(head(real_estate_df,5))
print(dim(real_estate_df))
attach(real_estate_df)
```

The dataset has 8 features:

1. city (qualitativa)
2. year (qualitativa su scala ordinale)
3. month (qualitativa su scala ordinale)
4. sales (quantitativa discreta)- number of saled house per that month
5. volume (quantitativa)- total revenue per that month in million of dollars
6. median_price (quantitativa)- median price in dollars
7. listings (quantitativa discreta)- total number of active listings
8. months_inventory (quantitativa continua)- amount of time required to sell all current listings

# 1. Features Analysis
```{r}
levels(city)
unique(year)
unique(month)
```
We have to analyze the result of four cities for four years, it is better to had a column that can combine year and month.
```{r}
real_estate_df$year_month <-paste(year, month, sep="_")
```

# 2. Indici di posizione, variabilità e forma 

```{r}
table(city)
table(year)
table(year, city)
table(month)
```

Le distribuzioni di frequenze assolute ci mostrano che i dati sono perfettamente bilanciati per anno e per città, quindi avremo un totale 60 entries per ogni città, una per ogni mese dei 5 anni di analisi.


Calcoliamo gli indici di posizione, di variabilità e di forma per le variabili: sales, volume, median_price, listing e months_inventory

```{r}
library(moments)
# Definizione funzione per il calcolo del coefficiente di variazione
CV <- function(x){
  return (sd(x)/mean(x))*100
}

# Lista delle colonne da analizzare
columns <- c("sales", "volume", "median_price", "listings", "months_inventory")

# Creazione di una lista per salvare i risultati
results <- list()

# Ciclo sulle colonne
for (col in columns) {
  
  data <- real_estate_df[[col]]  # Estrai la colonna
    
  # Calcola le statistiche base
  stats <- round(summary(data),2)  # Ottieni Min, Q1, Mediana, Media, Q3, Max
    
  # Calcola ulteriori statistiche
  iqr <- round(IQR(data),2)  # Intervallo interquartile
  varianza <- round(var(data),2)  # Varianza
  sd <- round(sd(data),2)  # Deviazione standard
  cv <- round(CV(data),2)
  skew <- round(skewness(data),2)  # Skewness
  kurt <- round(kurtosis(data),2)-3  # Kurtosis
    
    # Combina tutte le statistiche in una riga
  stats_row <- c(stats, IQR = iqr, Varianza = varianza, SD = sd, CV = cv, Skewness = skew, Kurtosis = kurt)
    
    # Trasponi per creare una riga per colonna e aggiungi alla lista
  results[[col]] <- as.data.frame(t(stats_row))

}

# Combina i risultati in un unico data.frame
results_table <- do.call(rbind, results)
results_table <- cbind(Grandezza = rownames(results_table), results_table)  # Aggiungi i nomi delle colonne
rownames(results_table) <- NULL  # Rimuovi i vecchi indici

# Aggiorna i nomi delle colonne per includere le nuove statistiche
colnames(results_table) <- c("Grandezza", "Min", "1st Qu.", "Median", "Mean", "3rd Qu.", "Max", 
                             "IQR", "Varianza", "SD", "CV", "Skewness", "Kurtosis")

# Visualizza il risultato
print(results_table)


```

# 3. Identificazione delle variabili con maggiore variabilità e asimmetria


Le grandezze sales. volume, listings e months_inventory mostrano tutte una asimmetria positiva in quanto la media è maggiore della mediana, mentre median_price mostra una asimmetria negativa. Le 5 quantità hanno domini di variabilità molto diversi.


Leggendo la colonna del coefficiente di variabilità possiamo notare che **volume** è la variabile con la più alta variabilità ed è anche quella che presente un coefficiente di asimmetria più alto, è anche l'unica con una Curtosi positiva (0.18) valore che ci dice come la variabile presenti la tendenza ad avere una distribuzione più stretta rispetto a quella della distribuzione normale. Validiamo queste osservazioni anche attraverso la rappresentazione grafica con istogrammi e boxplot.


Costruiamo gli istogrammi di queste sei grandezze:
```{r}
# Definizione per il calcolo del numero di bin secondo il criterio di Rice
rice_bins <- function(data) {
  n <- length(data) # Numero di osservazioni
  return(2 * n^(1/3))
}

```

```{r}
library(ggplot2)
library(patchwork) # Per disporre i grafici in una griglia

# Lista per salvare i grafici
plots <- list()

# Ciclo per generare gli istogrammi
for (col in columns) {
  
  data <- real_estate_df[[col]]
  
  # Calcola il numero di bin e il binwidth
  bins <- rice_bins(data)
  binwidth <- diff(range(data, na.rm = TRUE)) / bins
  
  # Crea l'istogramma
  plot <- ggplot(real_estate_df) +
    geom_histogram(aes_string(x = col),
                   binwidth = binwidth,
                   col = "black",
                   fill = "lightblue") +
    labs(title = paste("HS per", col),
         x = col,
         y = "Count") +
    theme_minimal()
  
  # Aggiungi il grafico alla lista
  plots[[col]] <- plot
}

# Disposizione dei grafici in una griglia 3x2
final_plot <- (plots[[1]] | plots[[2]] | plots[[3]]) /
              (plots[[4]] | plots[[5]])

# Mostra i grafici
print(final_plot)

  
```

Costruiamo i boxplot di queste sei grandezze:

```{r}
# Lista per salvare i grafici
plots <- list()

# Ciclo per generare gli istogrammi
for (col in columns) {
  
  data <- real_estate_df[[col]]
  
  # Crea l'istogramma
  plot <- ggplot(real_estate_df) +
    geom_boxplot(aes_string(y = col),
                   col = "black",
                   fill = "lightblue") +
    labs(title = paste("BP per", col),
         y = col) +
    theme_minimal()
  
  # Aggiungi il grafico alla lista
  plots[[col]] <- plot
}

# Disposizione dei grafici in una griglia 3x2
final_plot <- (plots[[1]] | plots[[2]] | plots[[3]]) /
              (plots[[4]] | plots[[5]])

# Mostra i grafici
print(final_plot)

```

Osservando i boxplot vediamo che **volume** è l'unica grandezza che presenta degli outliers, la presenza dei quali potrebbe giustificare l'asimetria registrata dal relativo coefficiente e la sua maggiore variabilità.

#4. Creazione di classi per una variabile quantitativa


Selezioniamo la variabile sales per costruire una distribuzione delle frequenza e determinare l'indice di eterogeneità di Gini.

```{r}
gini.index <- function(x){
  ni = table(x)
  fi = ni/length(x)
  fi2 = fi^2
  J = length(table(x))
  gini = 1 - sum(fi2)
  gini.normalizzato = gini/((J-1)/J)
  return(gini.normalizzato)
}

step_sales=(max(sales)-min(sales))/rice_bins(sales)
sales_cl <- cut(sales, seq(min(sales)-1, max(sales)+step_sales, step_sales))
n = length(sales_cl)

ni = table(sales_cl)
fi = table(sales_cl)/n
Ni = cumsum(ni)
Fi = Ni/n

dist_freq_sales <- as.data.frame(
  cbind(ni, fi, Ni, Fi)
)

dist_freq_sales$Intervalli <- rownames(dist_freq_sales)
dist_freq_sales$Intervalli <- factor(
  dist_freq_sales$Intervalli,  # Intervalli già presenti come stringhe
  levels = dist_freq_sales$Intervalli  # Ordine delle righe di dist_freq_sales
)
print(dist_freq_sales)

ggplot(dist_freq_sales, aes(x = Intervalli, y = fi)) +
  geom_bar(stat = "identity", fill = "steelblue") +
  xlab("Intervalli di Vendite") +
  ylab("Frequenza Relativa") +
  ggtitle("Distribuzione delle Vendite") +
  theme_minimal()+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


round(gini.index(dist_freq_sales$fi),4)
```


Studiando il barplot della distribuzione di frequenze relative della variabile sales, osserviamo che 5 delle 13 classi in cui abbiamo suddivido la variabile usando il criterio di Rice, presentano una frequenza tra il 10% e il 20%. Il campione quindi si presenta molto etereogeneo, come confermato anche dall'indice di eterogeneità di Gini che presenta un valore pari allo 0.9941.

# 5. Calcolo della probabilità

Vogliamo determinare alcune probabilità: la probabilità di avere un dato dalla città di "Beaumont", la probabilità di avere un dato estratto dal mese di Luglio e la probabilità di estrarre un dato di dicembre 2012.

```{r}
# Le tre probabilità che dobbiamo determinare possiamo tutte farle come casi favorevoli diviso casi possibile, cioè applicando la definisione di probabilità.

# Probabilità Beaumont
city_counts <- table(city)
p_Beaumont <- city_counts["Beaumont"]/length(city)
print(p_Beaumont)

# Probabilità Luglio
month_counts <- table(month)
p_July <- round(month_counts["7"]/length(month),3)
print(p_July)

# Probabilità Dicembre 2012
year_month_counts <-table(real_estate_df$year_month)
p_dic_2012 <- round(year_month_counts["2012_12"]/length(real_estate_df$year_month),3)
print(p_dic_2012) 
```

# 6. Creazione di nuove variabili

Vogliamo aggiungere una colonna al nostro dataset con il prezzo medio degli immobili. Per questo scopo useremo le features **volumes** e **sales** il loro rapporto moltiplicato per 10^6 ci permetterà di determinare il valore medio della vendita di una casa in dollari. 

```{r}
real_estate_df$mean_price <- volume*10^6/sales

bins <- rice_bins(real_estate_df$mean_price)
binwidth <- diff(range(real_estate_df$mean_price, na.rm = TRUE)) / bins

ggplot() +
  geom_histogram(aes_string(x = real_estate_df$mean_price),
                  binwidth = binwidth,
                  col = "black",
                  fill = "lightblue") +
  labs(title = paste("HS per Mean Price"),
        x = "Mean Price",
        y = "Count") +
  theme_minimal()

summary(real_estate_df$mean_price)
```

Dall'istogramma possiamo osservare che c'è una zona centrale (intorno a 160000 \$) dove si concentrano la maggior parte delle case ma che esiste anche un picco secondario attorno a 120000 \$, nonostante questo la distribuzione sembra avere una discreta simmetria, il valore mediano e la media sono molto vicini, il coefficiente di asimmetria in valore assoluto è minore di 0.1.

```{r}
round(skewness(real_estate_df$mean_price),3)
```


Vogliamo creare una variabile che descriva l'efficacia degli annunci di vendita. Potremmo dire che un annuncio è efficace se la casa è venduta in un minore quantitativo di tempo, sostanzialmente una campagna publicitaria è efficacia quando a parità di numero di annunci c'è una frequenza più alta di case vendute al mese. Per i dati che abbiamo possiamo definire l'indice che misura l'**efficacia degli annunci di vendita** come il rapporto tra il numero di annunci attivati quel mese - **listing** - e quanti mesi sono stati necessari per venderli tutti - **months_inventory**, più alto sarà questo valore più la campagna publicitaria è stata efficace. Prima di definire la nuova variabile osserviamo se effettivamente **listings** e **month_inventory** mostrano una qualche dipendenza:


```{r}
ggplot(data = real_estate_df, aes(x = listings, y = months_inventory)) +
  geom_point(color = "steelblue", size = 3, alpha = 0.7) +
  xlab("Listings") +
  ylab("Months Inventory") +
  ggtitle("Scatterplot di Listings vs Months Inventory") +
  theme_minimal()
```


Sono presenti tre serie di dati, segno di una dipendenza da qualche altro fattore probabilmente la città. Quindi riproduciamo il grafico precedente esplicitando la città di appartenza di ciascun dato (questo ci porta in modo naturale ad iniziare la nostra analisi condizionata).

# 7. Analisi condizionata

```{r}
ggplot(data = real_estate_df, aes(x = listings, y = months_inventory, color = city)) +
  geom_point(size = 3, alpha = 0.7) +
  xlab("Listings") +
  ylab("Months Inventory") +
  ggtitle("Scatterplot di Listings vs Months Inventory (per città)") +
  theme_minimal()+
  theme(legend.position = "right")
```


Come sospettavano, esplicitando la città di appartenenza, le due grandezze mostrano una molto probabile dipendenza lineare, quindi procediamo a definire il loro rapporto come l'indice di efficienza della campagna pubblicitaria:

```{r}
#Definizione della nuova variabile
real_estate_df$eff_ads <- listings/months_inventory
```


È interessante provare a vedere se c'è un correlazione tra il numero di annunci attivi e l'efficacia degli annunci stessi:


```{r}
ggplot(data = real_estate_df, aes(x = listings, y = eff_ads, color = city)) +
  geom_point(size = 3, alpha = 0.7) +
  xlab("Listings") +
  ylab("Effective Ads") +
  ggtitle("Scatterplot di Listings vs Effective Ads") +
  theme_minimal()+
  theme(legend.position = "right")
```


Il risultato è interessante, effettivamente c'è una certa correlazione tra il numero di annunci attivi e l'efficacia della campagna stessa. Proviamo a vedere invece la correlazione con i mesi necessari per vedere tutti gli annunci.

```{r}
ggplot(data = real_estate_df, aes(x = months_inventory, y = eff_ads, color = city)) +
  geom_point( size = 3, alpha = 0.7) +
  xlab("Months Inventory") +
  ylab("Effective Ads") +
  ggtitle("Scatterplot di Months Inventory vs Effective Ads") +
  theme_minimal()+
  theme(legend.position = "right")
```

All'interno della serie di dati relativi ad una stessa città si vede una correlazione inversa tra l'efficacia della campagna è i mesi necessari per vendere tutti gli annunci.

I due scatterplot ci testimoniano che la variabile che abbiamo definito riesce a descrivere l'efficacia di una campagna pubblicitaria.


Creiamo un summary di media e deviazione standard delle nostre nuove variabili in funzione della città.


```{r}
library(dplyr)
real_estate_df %>%
  group_by(city) %>%
  summarise(media_price = mean(mean_price),
            dev.st_price = sd(mean_price),
            media_eff_ads = mean(eff_ads),
            dev.st_eff_ads = sd(eff_ads))

```


Il summary prodotto mostra la differenza tra i prezzi delle case nelle quattro città e come anche l'efficacia della campagna pubblicitaria ha una certa dipendenza dalla città stessa.


Per chiarezza possiamo mostrare questo medesimo risultato attraverso dei boxplot:

```{r}
ggplot() +
    geom_boxplot(aes_string(y = real_estate_df$mean_price, color = city),
                   fill = "lightblue") +
    labs(title = paste("BP per Mean Price e città"),
         y = "Mean Price") +
    theme_minimal()+
    theme(legend.position = "bottom")

ggplot() +
    geom_boxplot(aes_string(y = real_estate_df$eff_ads, color = city),
                   fill = "lightblue") +
    labs(title = paste("BP per Eff Ads e città"),
         y = "Eff Ads") +
    theme_minimal()+
    theme(legend.position = "bottom")
```


Riproduciamo i boxplot del punto 3, aggiungendo la dipendenza dalla città:

```{r}
columns <- c("sales", "volume", "median_price", "listings", "months_inventory")

for (col in columns) {
  
  data <- real_estate_df[[col]]
  
  plot <- ggplot(real_estate_df) +
    geom_boxplot(aes_string(y = col, color = city),
                   fill = "lightblue") +
    labs(title = paste("BP per città e ", col),
         y = col) +
    theme_minimal()+
    theme(legend.position = "right")
  
  print(plot)

}

```


Per osservare se c'è una dipendenza dall'anno o dal mese oltre che dalla città, rappresentiamo le sette variabili (sales, volume, median_price, listings, months_inventory, mean_price e eff_ads) in funzione del tempo:


```{r}
# Converti la variabile year_month in un formato più leggibile
real_estate_df$year_month <- as.factor(real_estate_df$year_month)
real_estate_df$year_month <- gsub("_", "-", real_estate_df$year_month)  # Cambia '_' in '-'

# Aggiungi una colonna che converte il formato in Date per gestirlo meglio
real_estate_df$year_month_date <- as.Date(paste0(real_estate_df$year_month, "-01"), format="%Y-%m-%d")
# Ora possiamo usare ggplot2
# Colonne su cui fare i grafici
columns <- c("sales", "median_price", "listings", "eff_ads")

# Ciclo per creare un grafico per ogni colonna
for (col in columns) {
  # Crea il grafico
  p <- ggplot(real_estate_df, aes(x = year_month_date, y = !!sym(col), color = city, group = city)) +
    geom_line(linewidth = 1) +
    geom_point(size = 2) +
    xlab("Mese") +
    ylab(col) +
    ggtitle(sprintf("Andamento di %s nel tempo e per Città", col)) +
    scale_x_date(
      breaks = seq(min(real_estate_df$year_month_date), 
                   max(real_estate_df$year_month_date), 
                   by = "6 months"),  # Intervallo ogni 6 mesi
      labels = scales::date_format("%b %Y")  # Formato "Gennaio 2022"
    ) +
    theme_minimal() +
    theme(
      axis.text.x = element_text(angle = 45, hjust = 1)  # Ruota le etichette per maggiore leggibilità
    )
  
  # Stampa il grafico
  print(p)
}

```


Dal grafico della variabile sales si può osservare come le vendita abbiamo una certà periodicità infatti raggiungono il picco nel periodo estivo e il minimo durante l'inverno, per osservare meglio questo fenomeno rappresentiamolo attraverso un grafico a barre.

```{r}
# Crea un vettore con i nomi dei mesi
month_names <- c("Jannuary", "Febbrary", "March", "April", "May", "June", 
                 "July", "August", "September", "October", "November", "Dicember")

# Converte il numero del mese in nome del mese
real_estate_df$month_name <- factor(real_estate_df$month, levels = 1:12, labels = month_names)



ggplot(data = real_estate_df) +
  geom_bar(aes(x = month_name, y = sales, fill = city),
           position = "stack",  # Usato per le barre sovrapposte
           stat = "identity") +
  labs(title = "Distribuzione delle vendite nei mesi",
       x = "Mese",
       y = "Vendite totali") +
  scale_y_continuous(labels = scales::comma) +  # Formatta le etichette sull'asse y
  theme_classic() +
  theme(legend.position = "bottom")


ggplot(data = real_estate_df) +
  geom_bar(aes(x = month_name, y = sales, fill = city),
           position = "fill",  # Usa le barre normalizzate
           stat = "identity") +
  labs(title = "Distribuzione relativa delle vendite nei mesi",
       x = "Mese",
       y = "Frequenze relative") +
  scale_y_continuous(labels = scales::percent) +  # Mostra le frequenze come percentuali
  theme_classic() +
  theme(legend.position = "bottom")

```

